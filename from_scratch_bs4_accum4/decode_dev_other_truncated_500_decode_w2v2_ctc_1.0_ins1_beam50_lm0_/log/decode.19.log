# Running on cpu-p-172
# Started at Thu Jun 3 10:53:22 BST 2021
# SLURMD_NODENAME=cpu-p-172
# SLURM_ARRAY_JOB_ID=41632449
# SLURM_ARRAY_TASK_COUNT=32
# SLURM_ARRAY_TASK_ID=19
# SLURM_ARRAY_TASK_MAX=32
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=csd3
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=PATH
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=41632545
# SLURM_JOB_ACCOUNT=mlmi-xy316-sl2-cpu
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=18469
# SLURM_JOB_ID=41632545
# SLURM_JOB_NAME=decode.sh
# SLURM_JOB_NODELIST=cpu-p-172
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=cclake
# SLURM_JOB_QOS=cpu1
# SLURM_JOB_UID=18457
# SLURM_JOB_USER=xy316
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=3420
# SLURM_MPI_TYPE=pmi2
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=cpu-p-172
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SUBMIT_DIR=/rds/user/xy316/hpc-work/mphil/espnet/egs/librispeech/asr1
# SLURM_SUBMIT_HOST=login-e-13
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=161384
# SLURM_TOPOLOGY_ADDR=cpu-p-172
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=csd3:10.43.89.1:6817:8704:101
# asr_recog.py --config conf/decode_w2v2_ctc_1.0_ins1_beam50_lm0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 0 --recog-json /rds/user/xy316/hpc-work/mphil/espnet/egs/librispeech/asr1/decode_w2v2/dev_other_truncated_500/split32utt/data.19.json --result-label exp/train_librispeech_1h_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/decode_dev_other_truncated_500_decode_w2v2_ctc_1.0_ins1_beam50_lm0_/data.19.json --model exp/train_librispeech_1h_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/results/snapshot.ep.700 
2021-06-03 10:53:23,608 (asr_recog:288) WARNING: Skip DEBUG/INFO messages
2021-06-03 10:53:28,953 (asr_init:162) WARNING: reading model parameters from exp/train_librispeech_1h_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/results/snapshot.ep.700
2021-06-03 10:53:28,954 (nets_utils:422) WARNING: Subsampling is not performed for vgg*. It is performed in max pooling layers at CNN.
----Starting recoginition----
# Accounting: begin_time=1622714002
# Accounting: end_time=1622714424
# Accounting: time=422 threads=1
# Finished at Thu Jun 3 11:00:24 BST 2021 with status 0
