# Running on cpu-p-8
# Started at Fri Jun 4 10:06:05 BST 2021
# SLURMD_NODENAME=cpu-p-8
# SLURM_ARRAY_JOB_ID=41704304
# SLURM_ARRAY_TASK_COUNT=100
# SLURM_ARRAY_TASK_ID=65
# SLURM_ARRAY_TASK_MAX=100
# SLURM_ARRAY_TASK_MIN=1
# SLURM_ARRAY_TASK_STEP=1
# SLURM_CLUSTER_NAME=csd3
# SLURM_CPUS_ON_NODE=1
# SLURM_EXPORT_ENV=PATH
# SLURM_GET_USER_ENV=1
# SLURM_GTIDS=0
# SLURM_JOBID=41704569
# SLURM_JOB_ACCOUNT=mlmi-xy316-sl2-cpu
# SLURM_JOB_CPUS_PER_NODE=1
# SLURM_JOB_GID=18469
# SLURM_JOB_ID=41704569
# SLURM_JOB_NAME=decode.sh
# SLURM_JOB_NODELIST=cpu-p-8
# SLURM_JOB_NUM_NODES=1
# SLURM_JOB_PARTITION=cclake
# SLURM_JOB_QOS=cpu1
# SLURM_JOB_UID=18457
# SLURM_JOB_USER=xy316
# SLURM_LOCALID=0
# SLURM_MEM_PER_CPU=3420
# SLURM_MPI_TYPE=pmi2
# SLURM_NNODES=1
# SLURM_NODEID=0
# SLURM_NODELIST=cpu-p-8
# SLURM_NODE_ALIASES='(null)'
# SLURM_OPEN_MODE=a
# SLURM_PRIO_PROCESS=0
# SLURM_PROCID=0
# SLURM_SUBMIT_DIR=/rds/user/xy316/hpc-work/mphil/espnet/egs/librispeech/asr1
# SLURM_SUBMIT_HOST=login-e-12
# SLURM_TASKS_PER_NODE=1
# SLURM_TASK_PID=15006
# SLURM_TOPOLOGY_ADDR=cpu-p-8
# SLURM_TOPOLOGY_ADDR_PATTERN=node
# SLURM_WORKING_CLUSTER=csd3:10.43.89.1:6817:8704:101
# asr_recog.py --config conf/decode_w2v2_ctc_1.0_ins1_beam50_lm0.yaml --ngpu 0 --backend pytorch --debugmode 1 --verbose 0 --recog-json /rds/user/xy316/hpc-work/mphil/espnet/egs/librispeech/asr1/decode_w2v2/dev_other/split100utt/data.65.json --result-label exp/train_librispeech_10min_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/decode_dev_other_decode_w2v2_ctc_1.0_ins1_beam50_lm0_/data.65.json --model exp/train_librispeech_10min_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/results/snapshot.ep.3900 
2021-06-04 10:06:08,495 (asr_recog:288) WARNING: Skip DEBUG/INFO messages
2021-06-04 10:06:22,109 (asr_init:162) WARNING: reading model parameters from exp/train_librispeech_10min_pytorch_base_from_scratch_bs4_accum4_maskchannel0.25/results/snapshot.ep.3900
2021-06-04 10:06:22,110 (nets_utils:422) WARNING: Subsampling is not performed for vgg*. It is performed in max pooling layers at CNN.
----Starting recoginition----
# Accounting: begin_time=1622797565
# Accounting: end_time=1622798223
# Accounting: time=658 threads=1
# Finished at Fri Jun 4 10:17:03 BST 2021 with status 0
